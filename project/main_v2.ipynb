{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import libsumo as ls\n",
    "import traci\n",
    "import pandas as pd\n",
    "import platform\n",
    "# from time import time\n",
    "from collections import deque, defaultdict\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from xml.etree.ElementTree import Element, tostring, SubElement\n",
    "from xml.dom import minidom\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.batch_predict_action import batch_predict_v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataStructure:\n",
    "\n",
    "    def __init__(self, max_len: str = 20):\n",
    "\n",
    "        self.max_len = max_len\n",
    "\n",
    "        self.observations = deque(maxlen=max_len)\n",
    "        self.actions = deque(maxlen=max_len)\n",
    "        self.rewards = deque(maxlen=max_len)\n",
    "        self.dones = deque(maxlen=max_len)\n",
    "        self.t_steps = deque(maxlen=max_len)\n",
    "        self.target_return = deque(maxlen=max_len)\n",
    "\n",
    "    def add_observation(self, observation):\n",
    "        self.observations.append(observation)\n",
    "\n",
    "    def add_action(self, action):\n",
    "        self.actions.append(action)\n",
    "\n",
    "    def add_reward(self, reward):\n",
    "        self.rewards.append(reward)\n",
    "\n",
    "    def add_done(self, done):\n",
    "        self.dones.append(done)\n",
    "\n",
    "    def add_t_step(self, t_step):\n",
    "        self.t_steps.append(t_step)\n",
    "\n",
    "    def add_target_return(self, target_return):\n",
    "        self.target_return.append(target_return)\n",
    "\n",
    "    def reset(self):\n",
    "        self.observations.clear()\n",
    "        self.actions.clear()\n",
    "        self.rewards.clear()\n",
    "        self.dones.clear()\n",
    "        self.t_steps.clear()\n",
    "        self.target_return.clear()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.observations)\n",
    "    \n",
    "    def __getitem__(self, key):\n",
    "        if hasattr(self, key):\n",
    "            return list(getattr(self, key))\n",
    "        else:\n",
    "            raise KeyError(f\"Key '{key}' not found in DataStructure.\")\n",
    "\n",
    "    def __repr__(self):\n",
    "        return (f\"DataStructure(observations={list(self.observations)}, \"\n",
    "                f\"actions={list(self.actions)}, rewards={list(self.rewards)}, \"\n",
    "                f\"dones={list(self.dones)})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class car_controller():\n",
    "\n",
    "    _counter = 0 \n",
    "\n",
    "    def __init__(self,\n",
    "                 min_gap: float = 1.5,\n",
    "                 step_duration: float = 0.04,\n",
    "                 sim_duration_steps: int = 1800,\n",
    "                 traj_length: int = 20,\n",
    "                 max_episode_length: int = 4096,\n",
    "                 warm_up_duration: int = 900,\n",
    "                 gui: bool = False,\n",
    "                 begin_time: int = 27900, \n",
    "                 auto_start = True,\n",
    "                 quit_on_exit = True,\n",
    "                 network_file_path = \"./marios_net/athens_net_control.net.xml\",\n",
    "                 route_files = \"./marios_net/macro_routes_peak_demand_0.8_1.0_900_5400_0.7.rou.xml\",\n",
    "                 time_to_teleport = 300,\n",
    "                 scale = 0.7, \n",
    "                 ignore_junction_blocker = 60,\n",
    "                 rerouting_period = 180,\n",
    "                 routing_algorithm = \"astar\",\n",
    "                 rerouting_threads = 4,\n",
    "                 rerouting_pre_period = 0,\n",
    "                 rerouting_probability = 1,\n",
    "                 weights_priority_factor = 2,\n",
    "                 synchronize_rerouting = True,\n",
    "                 use_rerouting = False,\n",
    "                 no_internal_links = True,\n",
    "                 libsumo: bool = True,\n",
    "                 seed: int = 0,\n",
    "                 ignore_route_errors: bool = False,\n",
    "                 deactivate_lane_change: bool = False,\n",
    "                 activate_control: bool = True,\n",
    "                 sumo_output: bool = False,\n",
    "                 suffix: str = \"control\",\n",
    "                 sumo_output_folder: str = \"./sumo_results\",\n",
    "                 aggregation_period: int = 60,\n",
    "                 save_episode_stats: bool = True):\n",
    "        \n",
    "        self.label = car_controller._counter\n",
    "        car_controller._counter += 1\n",
    "\n",
    "        self.op_system = platform.system()\n",
    "        self.min_gap = min_gap\n",
    "        self.traj_length = traj_length\n",
    "        self.max_episode_length = max_episode_length\n",
    "        self.step_duration = step_duration\n",
    "        self.activate_control = activate_control\n",
    "        self.warm_up_duration = warm_up_duration\n",
    "        self.leader_max_comfortable_decel = 4.5\n",
    "        self.sim_duration_steps = sim_duration_steps\n",
    "        self.sumo_running = False\n",
    "        self.gui = gui\n",
    "        self.begin_time = begin_time\n",
    "        self.auto_start = auto_start\n",
    "        self.quit_on_exit = quit_on_exit\n",
    "        self.network_file_path = network_file_path\n",
    "        self.route_files = route_files\n",
    "        self.time_to_teleport = time_to_teleport\n",
    "        self.scale = scale\n",
    "        self.ignore_junction_blocker = ignore_junction_blocker\n",
    "        self.rerouting_period = rerouting_period\n",
    "        self.routing_algorithm = routing_algorithm\n",
    "        self.rerouting_threads = rerouting_threads\n",
    "        self.rerouting_pre_period = rerouting_pre_period\n",
    "        self.rerouting_probability = rerouting_probability\n",
    "        self.weights_priority_factor = weights_priority_factor\n",
    "        self.synchronize_rerouting = synchronize_rerouting\n",
    "        self.use_rerouting = use_rerouting\n",
    "        self.no_internal_links = no_internal_links\n",
    "        self.libsumo = libsumo\n",
    "        self.seed = seed\n",
    "        self.ignore_route_errors = ignore_route_errors\n",
    "        self.deactivate_lane_change = deactivate_lane_change\n",
    "        self.sumo_output = sumo_output\n",
    "        self.suffix = suffix\n",
    "        self.sumo_output_folder = sumo_output_folder\n",
    "        self.aggregation_period = aggregation_period\n",
    "        self.save_episode_stats = save_episode_stats\n",
    "\n",
    "        if self.sumo_output:\n",
    "            os.makedirs(self.sumo_output_folder, exist_ok=True)\n",
    "\n",
    "\n",
    "    def run_simulation(self):\n",
    "\n",
    "        if self.sumo_output:\n",
    "            self.edge_data_output_file_path = os.path.join(self.sumo_output_folder, f\"edge_data_output_{self.suffix}.xml\")\n",
    "            self.edge_data_add_file_path = os.path.join(self.sumo_output_folder, f\"edge_data_{self.suffix}.add.xml\")\n",
    "\n",
    "            self.create_edge_data_output_add_xml()\n",
    "\n",
    "        self.create_configuration()\n",
    "\n",
    "        self.start_sumo()\n",
    "\n",
    "        # Warm_up\n",
    "        for _ in tqdm(range(int(self.warm_up_duration//self.step_duration)), desc = \"Warm up steps:\"):\n",
    "            self.step_sim()\n",
    "\n",
    "        self.edge_id_list = self.sumo.edge.getIDList()\n",
    "\n",
    "        # Simulation\n",
    "        self.simulate()\n",
    "\n",
    "        self.close_sumo()\n",
    "\n",
    "        if self.sumo_output:\n",
    "            if os.path.exists(self.edge_data_add_file_path):\n",
    "                os.remove(self.edge_data_add_file_path)\n",
    "\n",
    "        if self.save_episode_stats: \n",
    "            with open(os.path.join(self.sumo_output_folder, f\"episode_stats_{self.suffix}.pkl\"), \"wb\") as f:\n",
    "                pickle.dump(self.episode_stats, f)\n",
    "\n",
    "\n",
    "    def state_neighbour(self,\n",
    "                        vehicle_ids: list[str]):\n",
    "        \n",
    "        RADIUS_NEIGHBOUR = 100\n",
    "        \n",
    "        positions = {follower_id: self.sumo.vehicle.getPosition(follower_id)\n",
    "                     for follower_id in vehicle_ids}\n",
    "        \n",
    "        speeds = {follower_id: self.sumo.vehicle.getSpeed(follower_id) for follower_id in vehicle_ids}\n",
    "\n",
    "        df_vehicles = pd.DataFrame.from_dict(positions, orient=\"index\", columns=[\"x\", \"y\"])\n",
    "        df_vehicles[\"speed\"] = pd.Series(speeds)\n",
    "\n",
    "        df_cross = df_vehicles.reset_index().merge(\n",
    "            df_vehicles.reset_index(), how=\"cross\", suffixes=(\"_ego\", \"_nbr\")\n",
    "        )\n",
    "\n",
    "        df_cross[\"distance\"] = (\n",
    "            (df_cross[\"x_ego\"] - df_cross[\"x_nbr\"]) ** 2\n",
    "            + (df_cross[\"y_ego\"] - df_cross[\"y_nbr\"]) ** 2\n",
    "        ) ** 0.5\n",
    "\n",
    "        df_neighbors = df_cross[df_cross[\"distance\"] <= RADIUS_NEIGHBOUR]\n",
    "\n",
    "        stats = (\n",
    "            df_neighbors.groupby(\"index_ego\")\n",
    "            .agg(\n",
    "                count_radius=(\"index_nbr\", \"count\"),\n",
    "                mean_speed_radius=(\"speed_nbr\", \"mean\"),\n",
    "                std_speed_radius=(\"speed_nbr\", \"std\"),\n",
    "                mean_dist_radius=(\"distance\", \"mean\"),\n",
    "                std_dist_radius=(\"distance\", \"std\"),\n",
    "            )\n",
    "            .fillna(0)\n",
    "        )\n",
    "\n",
    "        return stats.to_dict(\"index\")\n",
    "\n",
    "\n",
    "    def state_follower(self,\n",
    "                       vehicle_ids: list[str]):\n",
    "\n",
    "        \"\"\"State has the vehicle ids that we actually control as keys\"\"\"\n",
    "\n",
    "        state = {}\n",
    "\n",
    "        for follower_id in vehicle_ids:\n",
    "\n",
    "            follower_speed = self.sumo.vehicle.getSpeed(follower_id)\n",
    "            upcoming_tls = self.sumo.vehicle.getNextTLS(follower_id)\n",
    "\n",
    "            green_light = (\n",
    "                upcoming_tls[0][3] in {\"G\", \"g\", \"y\"} if len(upcoming_tls) != 0\n",
    "                else False\n",
    "            )\n",
    "\n",
    "            follower_accel = self.sumo.vehicle.getAcceleration(follower_id)\n",
    "            follower_edge = self.sumo.vehicle.getRoadID(follower_id)\n",
    "\n",
    "            leader = self.sumo.vehicle.getLeader(follower_id, 200.0)\n",
    "            if leader is None:\n",
    "                continue\n",
    "\n",
    "            leader_id, gap_minus_min_gap = leader\n",
    "            leader_edge = self.sumo.vehicle.getRoadID(leader_id)\n",
    "            gap = gap_minus_min_gap + self.min_gap\n",
    "            leader_speed = self.sumo.vehicle.getSpeed(leader_id)\n",
    "\n",
    "            kraus_follow_speed = self.sumo.vehicle.getFollowSpeed(\n",
    "                follower_id,\n",
    "                follower_speed,\n",
    "                gap + self.min_gap,\n",
    "                leader_speed,\n",
    "                self.leader_max_comfortable_decel,\n",
    "            )\n",
    "            leader_in_followers_subregion = follower_edge == leader_edge\n",
    "            local_reward = self.get_local_reward(follower_speed, kraus_follow_speed) * (\n",
    "                green_light or leader_in_followers_subregion\n",
    "            )\n",
    "\n",
    "            state[follower_id] = {\n",
    "                \"gap\": gap,\n",
    "                \"follower_speed\": follower_speed,\n",
    "                \"leader_speed\": leader_speed,\n",
    "                \"green_light\": int(green_light),\n",
    "                \"local_reward\": local_reward,\n",
    "                \"follower_accel\": follower_accel,\n",
    "            }\n",
    "\n",
    "        return state\n",
    "    \n",
    "\n",
    "    def get_flow_reward(self,\n",
    "        prev_edge_vehicle_count: dict[str, int],\n",
    "        curr_edge_vehicle_count: dict[str, int],\n",
    "    ) -> dict[str, int]:\n",
    "        \n",
    "        flow_rewards = {}\n",
    "        \n",
    "        for edge_id, _ in curr_edge_vehicle_count.items():\n",
    "            diff = curr_edge_vehicle_count[edge_id] - prev_edge_vehicle_count[edge_id]\n",
    "            flow_rewards[edge_id] = 1 if diff < 0 else 0\n",
    "\n",
    "        return flow_rewards\n",
    "    \n",
    "\n",
    "    def get_local_reward(self,\n",
    "                         follower_speed, v_safe):\n",
    "\n",
    "        SIGMA = 0.2\n",
    "\n",
    "        if follower_speed <= (1 - SIGMA) * v_safe:\n",
    "            return -1\n",
    "        if follower_speed <= v_safe:\n",
    "            return (1 / SIGMA / v_safe) * follower_speed - 1 / SIGMA\n",
    "        if follower_speed < (1 + SIGMA) * v_safe:\n",
    "            return -(1 / SIGMA / v_safe) * follower_speed + 1 / SIGMA\n",
    "        return -1\n",
    "    \n",
    "\n",
    "    def simulate(self):\n",
    "        \n",
    "        self.episode_stats = {\"ep_rew_total\": 0,\n",
    "                              \"ep_rew_local\": 0,\n",
    "                              \"ep_rew_global\": 0,\n",
    "                              \"ep_len\": 0,\n",
    "                              \"num_ep\": 0}\n",
    "\n",
    "        # for every edge: keep how many vehicles it has\n",
    "        prev_edge_vehicle_count = {\n",
    "            edge_id: self.sumo.edge.getLastStepVehicleNumber(edge_id)\n",
    "            for edge_id in self.edge_id_list\n",
    "        }\n",
    "\n",
    "        self.lane_deact_veh_id_list = set()\n",
    "        self.prev_edge_dict = dict()\n",
    "        self.trajectories = dict()\n",
    "        self.step_counter = dict()\n",
    "        self.stat_recorder = defaultdict(lambda: defaultdict(int))\n",
    "\n",
    "        for _ in tqdm(range(int(self.sim_duration_steps//self.step_duration)), desc = \"Simulation steps:\"):\n",
    "\n",
    "            self.step_sim()     \n",
    "\n",
    "            # all vehicles currently in the simulation\n",
    "            self.vehicle_id_list = list(self.sumo.vehicle.getIDList())\n",
    "            \n",
    "            for follower_id in self.vehicle_id_list:\n",
    "                if follower_id not in self.lane_deact_veh_id_list:\n",
    "                    self.lane_deact_veh_id_list.add(follower_id)\n",
    "                    if self.deactivate_lane_change:\n",
    "                        self.sumo.vehicle.setLaneChangeMode(follower_id, 0b001000000000) # TEST BEHAVIOR\n",
    "                    else:\n",
    "                        self.sumo.vehicle.setParameter(follower_id, \"laneChangeModel.lcSpeedGain\", str(0))\n",
    "\n",
    "            if not self.activate_control and not self.save_episode_stats:\n",
    "                continue\n",
    "\n",
    "            # vicinity state for all vehicles\n",
    "            veh_state_neighbour = self.state_neighbour(self.vehicle_id_list)\n",
    "\n",
    "            # follower state for all vehicles, keys are candidate vehicles to control\n",
    "            veh_state_follower = self.state_follower(self.vehicle_id_list)\n",
    "\n",
    "            # flow_rewards for all edges\n",
    "            curr_edge_vehicle_count = {\n",
    "                edge_id: self.sumo.edge.getLastStepVehicleNumber(edge_id)\n",
    "                for edge_id in self.edge_id_list\n",
    "            }\n",
    "            \n",
    "            flow_rewards = self.get_flow_reward(prev_edge_vehicle_count, curr_edge_vehicle_count)\n",
    "\n",
    "            # construct a step\n",
    "            batch = []\n",
    "            \n",
    "            # if \"warm_up_6380\" in self.vehicle_id_list and \"warm_up_6380\" not in veh_state_follower.keys():\n",
    "            #     print(\"Without follower.\")\n",
    "\n",
    "            \n",
    "            for vehicle_id in veh_state_follower.keys():\n",
    "\n",
    "                if vehicle_id in self.step_counter.keys() and \\\n",
    "                      self.step_counter[vehicle_id] >= self.max_episode_length:\n",
    "                    self.trajectories[vehicle_id].reset()\n",
    "                    self.step_counter[vehicle_id] = 0    \n",
    "                    continue\n",
    "\n",
    "                current_edge_of_vehicle = self.sumo.vehicle.getRoadID(vehicle_id)\n",
    "\n",
    "                end_episode_flag = False\n",
    "\n",
    "                if vehicle_id in self.prev_edge_dict.keys():\n",
    "                    if self.prev_edge_dict[vehicle_id] != current_edge_of_vehicle:\n",
    "                        end_episode_flag = True\n",
    "                        self.prev_edge_dict[vehicle_id] = current_edge_of_vehicle\n",
    "                else:\n",
    "                    self.prev_edge_dict[vehicle_id] = current_edge_of_vehicle\n",
    "\n",
    "                if vehicle_id not in self.trajectories.keys():\n",
    "                    self.trajectories[vehicle_id] = DataStructure(self.traj_length)\n",
    "                    self.step_counter[vehicle_id] = 0\n",
    "\n",
    "                if end_episode_flag:\n",
    "                    self.trajectories[vehicle_id].reset()\n",
    "                    self.step_counter[vehicle_id] = 0   \n",
    "                    self.stat_recorder.pop(vehicle_id)   \n",
    "                    self.update_stats(self.stat_recorder[vehicle_id])       \n",
    "\n",
    "                # step state\n",
    "                step_gap = veh_state_follower[vehicle_id][\"gap\"]\n",
    "                step_follower_speed = veh_state_follower[vehicle_id][\"follower_speed\"]\n",
    "                step_leader_speed = veh_state_follower[vehicle_id][\"leader_speed\"]\n",
    "                step_count_radius = veh_state_neighbour[vehicle_id][\"count_radius\"]\n",
    "                step_mean_speed_radius = veh_state_neighbour[vehicle_id][\"mean_speed_radius\"]\n",
    "                step_std_speed_radius = veh_state_neighbour[vehicle_id][\"std_speed_radius\"]\n",
    "                step_mean_dist_radius = veh_state_neighbour[vehicle_id][\"mean_dist_radius\"]\n",
    "                step_std_dist_radius = veh_state_neighbour[vehicle_id][\"std_dist_radius\"]\n",
    "                step_green_light = veh_state_follower[vehicle_id][\"green_light\"]\n",
    "\n",
    "                # step reward\n",
    "                step_local_reward = veh_state_follower[vehicle_id][\"local_reward\"]\n",
    "                step_global_reward = step_green_light * flow_rewards[current_edge_of_vehicle]\n",
    "                step_reward = step_local_reward + step_global_reward\n",
    "\n",
    "                self.stat_recorder[vehicle_id][\"rewards\"] += step_reward\n",
    "                self.stat_recorder[vehicle_id][\"local_rewards\"] += step_local_reward\n",
    "                self.stat_recorder[vehicle_id][\"global_rewards\"] += step_global_reward\n",
    "                self.stat_recorder[vehicle_id][\"ep_len\"] += 1\n",
    "\n",
    "                # step action\n",
    "                step_action = veh_state_follower[vehicle_id][\"follower_accel\"]\n",
    "\n",
    "                # trajectories\n",
    "                self.trajectories[vehicle_id].add_observation(\n",
    "                    [\n",
    "                        step_gap,\n",
    "                        step_follower_speed,\n",
    "                        step_leader_speed,\n",
    "                        step_count_radius,\n",
    "                        step_mean_speed_radius,\n",
    "                        step_std_speed_radius,\n",
    "                        step_mean_dist_radius,\n",
    "                        step_std_dist_radius,\n",
    "                        step_green_light,\n",
    "                    ]\n",
    "                )\n",
    "                self.trajectories[vehicle_id].add_action([step_action])\n",
    "                self.trajectories[vehicle_id].add_done(False)\n",
    "                self.trajectories[vehicle_id].add_reward(step_reward)\n",
    "\n",
    "                if self.step_counter[vehicle_id] == 0:\n",
    "                    self.trajectories[vehicle_id].add_target_return(0)\n",
    "                else:\n",
    "                    self.trajectories[vehicle_id].add_target_return(self.trajectories[vehicle_id].target_return[-1] - step_reward)\n",
    "\n",
    "                self.trajectories[vehicle_id].add_t_step(self.step_counter[vehicle_id])\n",
    "                \n",
    "                # the sauce\n",
    "                if len(self.trajectories[vehicle_id]) == 20:\n",
    "                    batch.append(vehicle_id)\n",
    "\n",
    "                self.step_counter[vehicle_id] += 1\n",
    "                    \n",
    "            # batch predict and control\n",
    "            if len(batch) and self.activate_control:\n",
    "                batch_preds = batch_predict_v2([self.trajectories[vehicle_id] for vehicle_id in batch], 0)\n",
    "                actions_batch = {vehicle_id: pa[0] for vehicle_id, pa in zip(batch, batch_preds)}\n",
    "\n",
    "                # control predicted actions\n",
    "                for vehicle_id, act in actions_batch.items():\n",
    "                        self.sumo.vehicle.setAcceleration(vehicle_id, act, self.step_duration)\n",
    "        \n",
    "    \n",
    "    def update_stats(self, dict_):\n",
    "\n",
    "        self.episode_stats[\"ep_rew_total\"] += dict_[\"rewards\"]\n",
    "        self.episode_stats[\"ep_rew_local\"] += dict_[\"local_rewards\"]\n",
    "        self.episode_stats[\"ep_rew_global\"] += dict_[\"global_rewards\"]\n",
    "        self.episode_stats[\"ep_len\"] += dict_[\"ep_len\"]\n",
    "        self.episode_stats[\"num_ep\"] += 1\n",
    "\n",
    "\n",
    "    def update(self):\n",
    "        \n",
    "        for veh_id in self.sumo.simulation.getArrivedIDList():\n",
    "            self.lane_deact_veh_id_list.remove(veh_id)\n",
    "            self.prev_edge_dict.pop(veh_id)\n",
    "            self.trajectories.pop(veh_id)\n",
    "            self.step_counter.pop(veh_id)\n",
    "            try:\n",
    "                self.stat_recorder.pop(veh_id)\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "\n",
    "    def prettify(self, elem):\n",
    "\n",
    "        rough_string = tostring(elem, 'utf-8')\n",
    "        reparsed = minidom.parseString(rough_string).toprettyxml(indent=\"  \")\n",
    "        \n",
    "        return reparsed\n",
    "\n",
    "\n",
    "    def create_edge_data_output_add_xml(self):\n",
    "        \n",
    "        root = Element(\"additional\")\n",
    "\n",
    "        SubElement(root, \"edgeData\", \n",
    "                   id = f\"edge_data_mfd\",\n",
    "                   file = os.path.abspath(self.edge_data_output_file_path),\n",
    "                   period = str(self.aggregation_period),\n",
    "                   excludeEmpty = \"defaults\")\n",
    "        \n",
    "        my_xml = self.prettify(root)\n",
    "        myfile = open(self.edge_data_add_file_path, \"w\")\n",
    "        myfile.write(my_xml)\n",
    "        myfile.close()\n",
    "\n",
    "\n",
    "    def step_sim(self):\n",
    "        self.sumo.simulationStep()\n",
    "\n",
    "\n",
    "    def start_sumo(self):\n",
    "        \n",
    "        if self.libsumo:\n",
    "            ls.start(self.sumo_cmd)\n",
    "            self.sumo = ls\n",
    "            self.sumo_running = True\n",
    "        else:\n",
    "            traci.start(self.sumo_cmd, label = self.label)\n",
    "            self.sumo = traci.getConnection(self.label)\n",
    "            self.sumo_running = True\n",
    "\n",
    "    \n",
    "    def close_sumo(self):\n",
    "\n",
    "        if self.sumo_running:\n",
    "            if self.libsumo:\n",
    "                ls.close()\n",
    "                self.sumo_running = False\n",
    "            else:\n",
    "                traci.switch(self.label)\n",
    "                traci.close(False)\n",
    "                self.sumo_running = False\n",
    " \n",
    "\n",
    "    def create_configuration(self):\n",
    "\n",
    "        self.sumo_cmd = [self.create_sumobinary()]\n",
    "\n",
    "        if self.auto_start:\n",
    "            self.sumo_cmd += [\"-S\"]\n",
    "\n",
    "        if self.quit_on_exit:\n",
    "            self.sumo_cmd += [\"-Q\"]\n",
    "\n",
    "        self.sumo_cmd += [\"-n\", self.network_file_path]\n",
    "\n",
    "        if isinstance(self.route_files, str):\n",
    "            self.sumo_cmd += [\"-r\", self.route_files]\n",
    "        else:\n",
    "            route_file_str = \"\"\n",
    "            for route_file in self.route_files:\n",
    "                route_file_str += route_file + \", \"\n",
    "            self.sumo_cmd += [\"-r\", route_file_str[:-2]]\n",
    "                        \n",
    "        self.sumo_cmd += [\"-b\", str(self.begin_time), \n",
    "                          \"--time-to-teleport\", str(self.time_to_teleport), \n",
    "                          '--no-warnings', 'True',\n",
    "                          \"--no-step-log\", 'True',\n",
    "                          \"--scale\", str(self.scale),\n",
    "                          \"--collision.action\", \"none\",\n",
    "                          \"--ignore-junction-blocker\", str(self.ignore_junction_blocker),\n",
    "                          \"--step-length\", str(self.step_duration)]\n",
    "        \n",
    "        if self.use_rerouting:\n",
    "            self.sumo_cmd += [\"--device.rerouting.period\", str(self.rerouting_period),\n",
    "                              \"--routing-algorithm\", self.routing_algorithm,\n",
    "                              \"--device.rerouting.threads\", str(self.rerouting_threads),\n",
    "                              \"--device.rerouting.pre-period\", str(self.rerouting_pre_period),\n",
    "                              \"--device.rerouting.probability\", str(self.rerouting_probability),\n",
    "                              \"--weights.priority-factor\", str(self.weights_priority_factor)]\n",
    "                        \n",
    "        if self.sumo_output:\n",
    "            self.sumo_cmd += [\"--tripinfo-output.write-unfinished\", \"true\",\n",
    "                              \"--tripinfo-output.write-undeparted\", \"true\",\n",
    "                              \"--statistic-output\", os.path.join(self.sumo_output_folder, f\"statistics_{self.suffix}.xml\"),\n",
    "                              \"--duration-log.statistics\", \"true\"]\n",
    "            \n",
    "            self.sumo_cmd += [\"-a\", self.edge_data_add_file_path]\n",
    "\n",
    "        if self.synchronize_rerouting:\n",
    "            self.sumo_cmd += [\"--device.rerouting.synchronize\", \"true\"]\n",
    "\n",
    "        if self.ignore_route_errors:\n",
    "            self.sumo_cmd += [\"--ignore-route-errors\", \"true\"]\n",
    "            \n",
    "        if self.no_internal_links:\n",
    "            self.sumo_cmd += [\"--no-internal-links\", \"true\"]\n",
    "\n",
    "        if self.seed is None:\n",
    "            self.sumo_cmd += [\"--random\"]\n",
    "        else:\n",
    "            self.sumo_cmd += [\"--seed\", str(self.seed)]\n",
    "\n",
    "\n",
    "    def create_sumobinary(self):\n",
    "        \n",
    "        if self.op_system == \"Windows\":\n",
    "            sumo_location = Path('C:\\Program Files (x86)') / 'Eclipse' / 'Sumo' / 'bin'\n",
    "        else:\n",
    "            sumo_location = Path('/usr/bin/')\n",
    "\n",
    "        if self.gui: \n",
    "            sumoBinary = sumo_location / 'sumo-gui.exe'\n",
    "        else:\n",
    "            sumoBinary = sumo_location / 'sumo.exe'\n",
    "\n",
    "        return str(sumoBinary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = car_controller(gui = False,\n",
    "                     libsumo = True,\n",
    "                     warm_up_duration = 900,\n",
    "                     step_duration = 1,\n",
    "                     sumo_output = True,\n",
    "                     suffix = \"control\",\n",
    "                     activate_control = True,\n",
    "                     sim_duration_steps = 1800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading net-file from './marios_net/athens_net_control.net.xml' ... done (88ms).\n",
      "Loading additional-files from './sumo_results/edge_data_control.add.xml' ... done (1ms).\n",
      "Loading done.\n",
      "Simulation version 1.20.0 started via libsumo with time: 27900.00.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warm up steps:: 100%|██████████| 900/900 [00:03<00:00, 276.65it/s] \n",
      "Simulation steps::   7%|▋         | 123/1800 [00:56<14:37,  1.91it/s]"
     ]
    }
   ],
   "source": [
    "env.run_simulation()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "perimeter_rl_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
